{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src='img/ms_logo.jpeg' height=40% width=40%></center>\n",
    "\n",
    "<center><h1>Supervised Learning with Decision Trees</h1></center>\n",
    "\n",
    "Now that we've built a classifier by hand, we have a general intuition behind the first Machine Learning algorithm we'll be using--[Decision Tree Classifiers](http://scikit-learn.org/stable/modules/tree.html#tree).  **_Decision Trees_** are considered one of the more mature, traditional algorithms in predictive analytics.  Although they can also be used for regression, you'll most likely see them used for classification problems.  \n",
    "\n",
    "Before we begin using one in code, please take a few minutes to check out [this great tutorial](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/) about how decision tress work.  \n",
    "<br>\n",
    "**_No, seriously.  Stop what you are doing and follow that link.  It contains one of the coolest visualizations of machine learning you'll ever see._**\n",
    "\n",
    "\n",
    "<center><h3>A Brief Primer on Decision Trees</h3></center>\n",
    "\n",
    "As explained in the SciKit-Learn user guide for this model, Decision Trees are \"a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.\" Let's explore what this means in plain English:\n",
    "\n",
    "* Decision Trees are **_non-parametric_**.  This means that they make no underlying assumptions about the distribution of the dataset that they are working with.  Non-parametric models are not necessarily better or worse than parametric models, just better suited for different use cases.  \n",
    "\n",
    "* Decision Trees can be used for **_Classification_** or **_Regression_**.  \n",
    "\n",
    "* Decision Trees make predictions by combining a series of simple decisions based on what it sees in the training data. These decisions are nested, to form a tree. In the last exercise, when you wrote your classifier by hand, you probably did the same thing. For instance, it's not uncommon for students to explain their handmade model by saying somnething like \"If the person I'm predicting for is a woman, I classify them as 'survived'.  If they're a man, I look at their ticket class.  If their ticket is 1st class, I predict they survived.  Otherwise, I predict they died\".  These nested sets of decisions can be represented as a tree, hence the name--Decision Tree!\n",
    "\n",
    "                                                        Male or Female?\n",
    "                                                          /           \\\n",
    "                                                         /             \\\n",
    "                                                Ticket Class?           SURVIVED!\n",
    "                                                /     |     \\\n",
    "                                            1st/   2nd|      \\3rd\n",
    "                                              /       |       \\\n",
    "                                        Survived     Died    Died\n",
    "                                        \n",
    "At the end of this notebook, we'll talk more deeply about the specifics of Decision Trees, and the benefits and drawbacks of this particular model.  For now, we'll start by importing the Titanic Dataset, cleaning it, and using a Decision Tree Classifier from the `SKLearn` library to make predictions on the data set!\n",
    "\n",
    "\n",
    "<center><h3>Preparing the Data Set</h3></center>\n",
    "\n",
    "We'll start by reading the dataset in using the `pandas` library.  After that, we'll take the following steps to prepare our dataset for use in a `DecisionTreeClassifier` from SKLearn.\n",
    "\n",
    "**_TASK:_** Read in the `titanic.csv` dataset from the `/datasets` folder.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to import the needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/titanic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we need to 'clean' the dataset to get it ready for a Decision Tree.  This steps consists of:\n",
    "\n",
    "1. Storing the 'Survived' column in a separate variable, and removing it from our Decision Tree.  This is what we are trying to predict, which means that we can't leave it in the dataset.  If we did, that would be like giving students the answer key along with the test--everyone would score 100% by default because of this column, and no actual learning would occur. \n",
    "<br>\n",
    "<br>\n",
    "2. Remove unecessary columns such as name, ticket number, etc.  Categorical features are fine, but features like name and ticket number provide no actual information, and will just confuse our algorithm.  Think about which columns should stay, and which should be dropped--in the cell below, we've provided a list of columns to drop for you. \n",
    "<br>\n",
    "<br>\n",
    "3.  Deal with NaN (null values).  In this case, we will deal with them just by dropping the entire row.  There are many other ways of dealing with NaNs, but they are outside the scope of this lesson.  \n",
    "<br>\n",
    "4. Convert categorical values to dummy columns (we've written this code for you)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that are not helpful\n",
    "columns_to_drop = ['PassengerId', 'Name', 'Ticket', 'Cabin']\n",
    "df_with_cols_dropped = df.drop(columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .dropna() to remove any rows that contain a null value\n",
    "clean_df = df_with_cols_dropped.dropna()\n",
    "\n",
    "# Use pd.get_dummies() on the clean_df object to create dummy columns for categorical variables.  Give the dummy\n",
    "# columns the prefix 'is_' to make it clear that they are dummy varibles. \n",
    "clean_df = pd.get_dummies(clean_df, prefix='is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the 'Survived' column in the 'labels' variable\n",
    "labels = clean_df['Survived']\n",
    "\n",
    "# Uncomment and run the code below to drop the 'Survived' column from the clean_df dataframe.  \n",
    "clean_df.drop('Survived', axis=1, inplace=True)\n",
    "\n",
    "# Ignore the warning pandas gives you when you run this cell--everything is fine.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>Recap: What We've Done So Far</h3></center>\n",
    "\n",
    "We've now gone through the steps to 'clean' our dataset, and we're almost ready to begin using our Decision Tree Classifier. Let's look at what we've done so far.  \n",
    "\n",
    "1.  Dropped the non-numeric columns.  We can safely assume that no useful information is contained in text-based columns such as name, cabin, etc, so we've dropped them.  \n",
    "2.  Removed rows containing null values. \n",
    "3.  Used. `pd.get_dummies()` to convert categorical columns such as 'Sex' and 'Embarked' into columns for each category, with the category for the actual value containing a '1' while all other dummy columns for that category for that column will contain a '0'.\n",
    "4.  Stored the labels in a separate data set.  It is important that we do this last.  Otherwise, any changes that we make to the corresponding rows in the dataframe will not be reflected in our labels variable.  For instance, if we stored labels in a separate variable and _then_ dropped rows from the dataframe that contain null values, we would still have those corresponding labels for the passengers we've dropped from the dataframe! Separating out our labels only works if the labels for each correspond to the row at the same index in the dataframe.\n",
    "\n",
    "Here's what we'll do next: \n",
    "\n",
    "1. Import the appropriate tools from the `sklearn` library.  We need `train_test_split` to split our data set into training and testing sets,  the actual `DecisionTreeClassifier` model, and `f1_score` to tell us how we did.  \n",
    "<br>\n",
    "2.  Split our data into a **_Training Set_** and a **_Testing Set_**.  Our model will 'learn' on the training set, but we don't want to use this as a metric to tell us how well our model actually does.  In order to see how well our model actually 'learned' how to make predictions, we'll split off a portion of our data to hold out as a testing set.  Our model will make predictions on this data, which gives us a better signal as to whether our model is **_overfitting_**. We'll talk about the concept of **_overfitting_** and **_underfitting_** in a later class.  \n",
    "<br> \n",
    "3.  We'll create a `DecisionTreeClassifier()` object.  \n",
    "<br> \n",
    "4.  We'll `fit()` our model by feeding in our `X_Train` and `y_train` variables.  \n",
    "<br>\n",
    "5.  We'll ask our classifier object to make predictions for every object in the `X_test` variable.   \n",
    "<br>\n",
    "6.  We'll use the `f1_score` object to tell us how well our model made predictions by giving it the predictions made in the last step, as well as the actual labels for those data points, which are currently stored in `y_test`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73750000000000004"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(clean_df, labels)\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Call clf.fit(), and pass in X_train and y_train as parameters\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Use the .predict() method to have our model create predictions on the X_test variable\n",
    "test_pred = clf.predict(X_test) \n",
    "\n",
    "# Finally, pass in test_pred and y_test to the f1_score() object to get an f1_score!\n",
    "score = f1_score(test_pred, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>Branching Out on Your Own</h3></center>\n",
    "\n",
    "Congratulations! You've now successfully used your first Machine Learning algorithm. VC's will now shower you with money any time you say \"Machine Learning\" out loud.\n",
    "\n",
    "<center><img src='img/make_it_rain.gif'></center>\n",
    "\n",
    "<center>Doing Supervised Learning, Unsupervised</center>\n",
    "\n",
    "For the final challenge in this notebook, you'll use a decision tree classifier to make predictions on the Iris Dataset.  The process will be entirely the same as we did on the Titanic dataset, but easier because it requires less data cleaning.  (Hint: Take a look at the [sklearn.datasets](http://scikit-learn.org/stable/datasets/index.html) page to see if you can save yourself some time!)\n",
    "\n",
    "Use a _Decision Tree Classifier_ to try and predict the class of each flower in the Iris dataset.  Use the same methodology you used for the Titanic dataset to get things up and running.\n",
    "\n",
    "**_BONUS:_** See if you can **_visualize_** the Decision Tree you've created!  You can find example code on how to do this fairly easily on the [sklearn's documentation page for Decision Trees](http://scikit-learn.org/stable/modules/tree.html#tree).  Here's an example of visualization from the page:\n",
    "\n",
    "<center><img src='http://scikit-learn.org/stable/_images/iris.svg' height=75% width=75%></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97.368421052631575, 97.217391304347828, 97.372997711670479)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the Iris dataset from sklearn and use a decision tree classifier below!\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris(True)\n",
    "data[0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[0], data[1])\n",
    "\n",
    "iris_clf = DecisionTreeClassifier()\n",
    "\n",
    "# Call clf.fit(), and pass in X_train and y_train as parameters\n",
    "iris_clf.fit(X_train, y_train)\n",
    "\n",
    "# Use the .predict() method to have our model create predictions on the X_test variable\n",
    "test_pred = iris_clf.predict(X_test) \n",
    "\n",
    "# Finally, pass in test_pred and y_test to the f1_score() object to get an f1_score!\n",
    "score = f1_score(test_pred, y_test, average='micro') * 100\n",
    "score2 = f1_score(test_pred, y_test, average='macro') * 100\n",
    "score3 = f1_score(test_pred, y_test, average='weighted') * 100\n",
    "score, score2, score3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"523pt\" height=\"671pt\"\n",
       " viewBox=\"0.00 0.00 523.00 671.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 667)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-667 519,-667 519,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"transparent\" stroke=\"#000000\" d=\"M273,-663C273,-663 174,-663 174,-663 168,-663 162,-657 162,-651 162,-651 162,-592 162,-592 162,-586 168,-580 174,-580 174,-580 273,-580 273,-580 279,-580 285,-586 285,-592 285,-592 285,-651 285,-651 285,-657 279,-663 273,-663\"/>\n",
       "<text text-anchor=\"start\" x=\"170\" y=\"-647.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">petal width (cm) ≤ 0.75</text>\n",
       "<text text-anchor=\"start\" x=\"196\" y=\"-632.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.666</text>\n",
       "<text text-anchor=\"start\" x=\"189\" y=\"-617.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 112</text>\n",
       "<text text-anchor=\"start\" x=\"178.5\" y=\"-602.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [36, 38, 38]</text>\n",
       "<text text-anchor=\"start\" x=\"183\" y=\"-587.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#e58139\" stroke=\"#000000\" d=\"M195.5,-536.5C195.5,-536.5 125.5,-536.5 125.5,-536.5 119.5,-536.5 113.5,-530.5 113.5,-524.5 113.5,-524.5 113.5,-480.5 113.5,-480.5 113.5,-474.5 119.5,-468.5 125.5,-468.5 125.5,-468.5 195.5,-468.5 195.5,-468.5 201.5,-468.5 207.5,-474.5 207.5,-480.5 207.5,-480.5 207.5,-524.5 207.5,-524.5 207.5,-530.5 201.5,-536.5 195.5,-536.5\"/>\n",
       "<text text-anchor=\"start\" x=\"139\" y=\"-521.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"129\" y=\"-506.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 36</text>\n",
       "<text text-anchor=\"start\" x=\"121.5\" y=\"-491.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [36, 0, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"127\" y=\"-476.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = setosa</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M201.4657,-579.8796C195.6442,-568.8835 189.3473,-556.9893 183.4773,-545.9015\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"186.4389,-544.0152 178.6667,-536.8149 180.2524,-547.2905 186.4389,-544.0152\"/>\n",
       "<text text-anchor=\"middle\" x=\"171.3146\" y=\"-557.0094\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"transparent\" stroke=\"#000000\" d=\"M337,-544C337,-544 238,-544 238,-544 232,-544 226,-538 226,-532 226,-532 226,-473 226,-473 226,-467 232,-461 238,-461 238,-461 337,-461 337,-461 343,-461 349,-467 349,-473 349,-473 349,-532 349,-532 349,-538 343,-544 337,-544\"/>\n",
       "<text text-anchor=\"start\" x=\"234\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">petal width (cm) ≤ 1.75</text>\n",
       "<text text-anchor=\"start\" x=\"266\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"256\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 76</text>\n",
       "<text text-anchor=\"start\" x=\"245.5\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 38, 38]</text>\n",
       "<text text-anchor=\"start\" x=\"247\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M245.8841,-579.8796C250.4856,-571.3236 255.3796,-562.2238 260.1342,-553.3833\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"263.3662,-554.763 265.0204,-544.2981 257.2012,-551.4473 263.3662,-554.763\"/>\n",
       "<text text-anchor=\"middle\" x=\"272.2161\" y=\"-564.5401\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#39e581\" fill-opacity=\"0.894118\" stroke=\"#000000\" d=\"M274,-425C274,-425 171,-425 171,-425 165,-425 159,-419 159,-413 159,-413 159,-354 159,-354 159,-348 165,-342 171,-342 171,-342 274,-342 274,-342 280,-342 286,-348 286,-354 286,-354 286,-413 286,-413 286,-419 280,-425 274,-425\"/>\n",
       "<text text-anchor=\"start\" x=\"167\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">petal length (cm) ≤ 4.95</text>\n",
       "<text text-anchor=\"start\" x=\"195\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.172</text>\n",
       "<text text-anchor=\"start\" x=\"191\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 42</text>\n",
       "<text text-anchor=\"start\" x=\"183.5\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 38, 4]</text>\n",
       "<text text-anchor=\"start\" x=\"182\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M264.7662,-460.8796C260.0435,-452.2335 255.0176,-443.0322 250.141,-434.1042\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"253.1963,-432.3964 245.3309,-425.2981 247.053,-435.752 253.1963,-432.3964\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<path fill=\"#8139e5\" stroke=\"#000000\" d=\"M386.5,-417.5C386.5,-417.5 316.5,-417.5 316.5,-417.5 310.5,-417.5 304.5,-411.5 304.5,-405.5 304.5,-405.5 304.5,-361.5 304.5,-361.5 304.5,-355.5 310.5,-349.5 316.5,-349.5 316.5,-349.5 386.5,-349.5 386.5,-349.5 392.5,-349.5 398.5,-355.5 398.5,-361.5 398.5,-361.5 398.5,-405.5 398.5,-405.5 398.5,-411.5 392.5,-417.5 386.5,-417.5\"/>\n",
       "<text text-anchor=\"start\" x=\"330\" y=\"-402.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"320\" y=\"-387.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 34</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-372.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 0, 34]</text>\n",
       "<text text-anchor=\"start\" x=\"314\" y=\"-357.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>2&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M309.8841,-460.8796C315.798,-449.8835 322.1949,-437.9893 328.158,-426.9015\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"331.3908,-428.2799 333.0449,-417.8149 325.2258,-424.9642 331.3908,-428.2799\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#39e581\" fill-opacity=\"0.972549\" stroke=\"#000000\" d=\"M202,-306C202,-306 103,-306 103,-306 97,-306 91,-300 91,-294 91,-294 91,-235 91,-235 91,-229 97,-223 103,-223 103,-223 202,-223 202,-223 208,-223 214,-229 214,-235 214,-235 214,-294 214,-294 214,-300 208,-306 202,-306\"/>\n",
       "<text text-anchor=\"start\" x=\"99\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">petal width (cm) ≤ 1.65</text>\n",
       "<text text-anchor=\"start\" x=\"125\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.053</text>\n",
       "<text text-anchor=\"start\" x=\"121\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 37</text>\n",
       "<text text-anchor=\"start\" x=\"113.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 36, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"112\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M198.0174,-341.8796C192.9315,-333.2335 187.5189,-324.0322 182.2672,-315.1042\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"185.1741,-313.1428 177.0871,-306.2981 179.1406,-316.692 185.1741,-313.1428\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<path fill=\"#8139e5\" fill-opacity=\"0.333333\" stroke=\"#000000\" d=\"M343,-306C343,-306 244,-306 244,-306 238,-306 232,-300 232,-294 232,-294 232,-235 232,-235 232,-229 238,-223 244,-223 244,-223 343,-223 343,-223 349,-223 355,-229 355,-235 355,-235 355,-294 355,-294 355,-300 349,-306 343,-306\"/>\n",
       "<text text-anchor=\"start\" x=\"240\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">petal width (cm) ≤ 1.55</text>\n",
       "<text text-anchor=\"start\" x=\"269\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.48</text>\n",
       "<text text-anchor=\"start\" x=\"265\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5</text>\n",
       "<text text-anchor=\"start\" x=\"257\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 2, 3]</text>\n",
       "<text text-anchor=\"start\" x=\"256\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>3&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M247.3324,-341.8796C252.4909,-333.2335 257.9808,-324.0322 263.3076,-315.1042\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"266.4436,-316.679 268.5617,-306.2981 260.4322,-313.0924 266.4436,-316.679\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#39e581\" stroke=\"#000000\" d=\"M85,-179.5C85,-179.5 12,-179.5 12,-179.5 6,-179.5 0,-173.5 0,-167.5 0,-167.5 0,-123.5 0,-123.5 0,-117.5 6,-111.5 12,-111.5 12,-111.5 85,-111.5 85,-111.5 91,-111.5 97,-117.5 97,-123.5 97,-123.5 97,-167.5 97,-167.5 97,-173.5 91,-179.5 85,-179.5\"/>\n",
       "<text text-anchor=\"start\" x=\"27\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"17\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 36</text>\n",
       "<text text-anchor=\"start\" x=\"9.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 36, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M116.1258,-222.8796C106.1314,-211.4436 95.288,-199.0363 85.2714,-187.575\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"87.7055,-185.0414 78.4895,-179.8149 82.4347,-189.6479 87.7055,-185.0414\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"#8139e5\" stroke=\"#000000\" d=\"M194,-179.5C194,-179.5 127,-179.5 127,-179.5 121,-179.5 115,-173.5 115,-167.5 115,-167.5 115,-123.5 115,-123.5 115,-117.5 121,-111.5 127,-111.5 127,-111.5 194,-111.5 194,-111.5 200,-111.5 206,-117.5 206,-123.5 206,-123.5 206,-167.5 206,-167.5 206,-173.5 200,-179.5 194,-179.5\"/>\n",
       "<text text-anchor=\"start\" x=\"139\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"132\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n",
       "<text text-anchor=\"start\" x=\"124\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 0, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"123\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M155.298,-222.8796C156.0151,-212.2134 156.7889,-200.7021 157.515,-189.9015\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"161.0144,-190.0272 158.1931,-179.8149 154.0301,-189.5576 161.0144,-190.0272\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<path fill=\"#8139e5\" stroke=\"#000000\" d=\"M319,-179.5C319,-179.5 252,-179.5 252,-179.5 246,-179.5 240,-173.5 240,-167.5 240,-167.5 240,-123.5 240,-123.5 240,-117.5 246,-111.5 252,-111.5 252,-111.5 319,-111.5 319,-111.5 325,-111.5 331,-117.5 331,-123.5 331,-123.5 331,-167.5 331,-167.5 331,-173.5 325,-179.5 319,-179.5\"/>\n",
       "<text text-anchor=\"start\" x=\"264\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"257\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n",
       "<text text-anchor=\"start\" x=\"249\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 0, 2]</text>\n",
       "<text text-anchor=\"start\" x=\"248\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>7&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M290.702,-222.8796C289.9849,-212.2134 289.2111,-200.7021 288.485,-189.9015\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"291.9699,-189.5576 287.8069,-179.8149 284.9856,-190.0272 291.9699,-189.5576\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<path fill=\"#39e581\" fill-opacity=\"0.498039\" stroke=\"#000000\" d=\"M466,-187C466,-187 361,-187 361,-187 355,-187 349,-181 349,-175 349,-175 349,-116 349,-116 349,-110 355,-104 361,-104 361,-104 466,-104 466,-104 472,-104 478,-110 478,-116 478,-116 478,-175 478,-175 478,-181 472,-187 466,-187\"/>\n",
       "<text text-anchor=\"start\" x=\"357\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">sepal length (cm) ≤ 6.95</text>\n",
       "<text text-anchor=\"start\" x=\"386\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.444</text>\n",
       "<text text-anchor=\"start\" x=\"385\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3</text>\n",
       "<text text-anchor=\"start\" x=\"377\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 2, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"373\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>7&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M335.4702,-222.8796C344.7338,-213.6931 354.6296,-203.8798 364.1552,-194.4336\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"366.7146,-196.8247 371.3507,-187.2981 361.7856,-191.8543 366.7146,-196.8247\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<path fill=\"#39e581\" stroke=\"#000000\" d=\"M394,-68C394,-68 321,-68 321,-68 315,-68 309,-62 309,-56 309,-56 309,-12 309,-12 309,-6 315,0 321,0 321,0 394,0 394,0 400,0 406,-6 406,-12 406,-12 406,-56 406,-56 406,-62 400,-68 394,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"336\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"329\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2</text>\n",
       "<text text-anchor=\"start\" x=\"321\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 2, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"317\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M392.6477,-103.9815C388.2625,-95.2504 383.6267,-86.0202 379.211,-77.2281\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"382.3246,-75.6291 374.7087,-68.2637 376.0692,-78.7708 382.3246,-75.6291\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<path fill=\"#8139e5\" stroke=\"#000000\" d=\"M503,-68C503,-68 436,-68 436,-68 430,-68 424,-62 424,-56 424,-56 424,-12 424,-12 424,-6 430,0 436,0 436,0 503,0 503,0 509,0 515,-6 515,-12 515,-12 515,-56 515,-56 515,-62 509,-68 503,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"448\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"441\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n",
       "<text text-anchor=\"start\" x=\"433\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 0, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"432\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>9&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M434.3523,-103.9815C438.7375,-95.2504 443.3733,-86.0202 447.789,-77.2281\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"450.9308,-78.7708 452.2913,-68.2637 444.6754,-75.6291 450.9308,-78.7708\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x10c9a6ac8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize Decision Tree\n",
    "import graphviz\n",
    "from sklearn import tree\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "dot_data = tree.export_graphviz(iris_clf, out_file=None, \n",
    "                         feature_names=iris.feature_names,  \n",
    "                         class_names=iris.target_names,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)\n",
    "\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
