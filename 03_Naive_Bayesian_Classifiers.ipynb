{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src='img/ms_logo.jpeg' height=40% width=40%></center>\n",
    "\n",
    "<center><h1>Naive Bayesian Classifiers</h1></center>\n",
    "\n",
    "In this notebook, we'll be focusing on **_Naive Bayesian Classifiers_**, or \"Naive Bayes\" for short.  This is an algorithm that uses **_Bayes' Theorem_** to make a classification based on probability.  In case you're unfamiliar with Bayes' Theorem, let's look at the formula:\n",
    "<br>\n",
    "<br>\n",
    "<center><img src='img/bayes_theorem.png' height=40% width=40%></center>\n",
    "<br>\n",
    "<br>\n",
    "Don't worry if you've seen this mathematical notation before. In plain English, that formula reads:\n",
    "\n",
    "\"The probability of A given B equals the probability of B given A, times the probability of A, divided by the probability of B\".  \n",
    "\n",
    "Let's run through an example case here and see if we can demystify this equation a little bit more. \n",
    "\n",
    "<center><h3>Scenario: Spam Detection</h3></center>\n",
    "\n",
    "We have a dataset of emails, and we're trying to build a classifier that can predict if an email is spam or not by examining the words based in the emails.  Each email in our training set has been labeled as \"spam\" or \"ham\" (a real email, not spam).  We've counted each word used in every email, and found the following:\n",
    "\n",
    "**_65% of the emails in the dataset are \"Spam\"._**\n",
    "\n",
    "**_\"Spam\"_** emails contain the word _\"deal\"_ 80% of the time, and _\"win\"_ 40% of the time.  \n",
    "\n",
    "**_35% of the emails in the datasert are \"Ham\"._**\n",
    "\n",
    "**_\"Ham\"_** emails contain the word _\"deal\"_ 17% of the time, and _\"win\"_ 6% of the time.  \n",
    "\n",
    "The next email we try to predict contains the both words \"deal\" and \"win\". Given the information above, we can plug these numbers into Bayes' Theorem and predict the likelihood that this is email Spam. \n",
    "\n",
    "<center>P(Spam|deal, win) = (P(win, deal|Spam) * P(Spam)) / P(deal, win)</center>\n",
    "\n",
    "This can be further broken down into: \n",
    "<br>\n",
    "<br>\n",
    "<center>P(Spam|deal) \\* P(Spam|win) = P(deal|Spam) \\* P(Spam) \\*  P(win|Spam) \\* P(Spam) / P(deal|Spam) + P(deal|!Spam) \\* P(win|Spam) + P(win|!Spam)</center>\n",
    "\n",
    "In the equation above, \"P(deal|!Spam)\" can be read as \"the percentage that 'deal' occurs in 'Ham' emails\".  \n",
    "\n",
    "On the next step, we'll start defining the probabilities for everything in that equation so we can plug them in:\n",
    "\n",
    "1. P(deal|Spam) = .8\n",
    "1. P(win|Spam) = .4\n",
    "1. P(Spam) = .65\n",
    "1. P(deal|!Spam) = .17\n",
    "1. P(win|!Spam) = .06\n",
    "1. P(!Spam) = .35\n",
    "\n",
    "Let's replace some of these terms with the probabilities listed above and see how it works out:\n",
    "<br>\n",
    "<br>\n",
    "<center>(.8 \\* .65 \\* .4 \\* .65) / .8 \\* .65 + .35 \\* .17 \\* .4 \\* .65 + .35 \\* .6 = **0.922595** </center>\n",
    "<br>\n",
    "<br>\n",
    "Based on the math from Bayes' Theorem, we can predict probability that a new email containing both \"deal\" and \"win\" is \"Spam\" is approximately **92.2%**!\n",
    "\n",
    "<center><h3>Using Naive Bayes in the Real World</h3></center>\n",
    "\n",
    "In the above example, we did the math by hand.  That isn't very practical in the real world.  Luckily, `sklearn` contains some awesome implementations of Naive Bayesian Classifiers (and regressors!).  \n",
    "\n",
    "For this assignment, we're going to use a `GaussianNB()` object.  There are a few different kinds of Naive Bayesian Classifiers, but for this one we'll stick to one that assumes our data follows a Gaussian (normal) distribution.  \n",
    "\n",
    "Let's Get Started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 1]\n",
      "[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 1]\n",
      "accuracy score: 1.0\n",
      "f1 score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "# Use load_iris() to load the data into the iris variable, and then assign iris.data and iris.target to the appropriate\n",
    "# variables\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "labels = iris.target\n",
    "\n",
    "# Use train_test_split to split the data into X_train, X_test, y_train, and y_test variables\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels)\n",
    "\n",
    "# Create a GaussianNB() object and fit it using the training data\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Use the fitted model to create predictions for the X_test data.\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "\n",
    "# Run it all and see how you did!\n",
    "print(preds)\n",
    "print(y_test)\n",
    "print(\"accuracy score: {}\".format(accuracy_score(y_test, preds)))\n",
    "print(\"f1 score: {}\".format(f1_score(y_test, preds, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>Some Caveats</h3></center>\n",
    "\n",
    "You may have wondered why this particular model is a called a **_Naive_** Bayesian Classifier.  In this scenario, the word \"Naive\" simply means that the model makes the \"naive\" assumption that all features are independent of one another.  This leads us to the main caveat of this model--if you have feature columns that are highly correlated, this model may not work as well as we'd like.  **_If you're going to use Naive Bayes, make sure you check for highly correlated features beforehand!_**\n",
    "\n",
    "\n",
    "<center><h3>Where to Go From Here</h3></center>\n",
    "\n",
    "For the latter part of this assignment, you're going to use the famous Pima Indians Diabetes Dataset to build a Naive Bayesian Classifier that predicts whether or not an individual has diabetes.  You'll find the `pima_indians_diabetes.csv` file inside the `datasets` folder.  \n",
    "\n",
    "To build this classifier successfully, you'll want to follow the best practices for loading in and preprocessing a data set that you've learned in class:\n",
    "\n",
    "1. Importing the data\n",
    "1. Exploring the data\n",
    "1. \"Cleaning\" the data\n",
    "1. Splitting the data into training and testing sets (or using KFold Cross val--more on this below)\n",
    "1. Fitting the model\n",
    "1. Validating the model (checking predictions on the test set)\n",
    "\n",
    "Be sure to consider the following questions as you solve this problem:\n",
    "\n",
    "* How will you deal with null values?\n",
    "* For this model, does scaling the data improve your results? (HINT: test your assumption!)\n",
    "\n",
    "On top of cleaning and preprocessing this data set, you'll also use **_Cross Validation_** to get a better measure of the accuracy of your model.  We did not use K Fold Cross Validation in the above model on purpose--instead, you'll need to work your way through `sklearn`'s [model_selection documentation](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection) to figure out how to effectively make use of cross-validation.  \n",
    "\n",
    "(**_Hint:_** There are several ways to implement cross validation using sklearn.  In the `model_selection` section of the documentation, pay special attention to the `KFold` object, as well as the methods available under the _Model Selection_ subsection.)\n",
    "\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path to file: \"datasets/pima_indians_diabetes.csv\". The first row of the .csv contains the column names.\n",
    "# Note that in the \"Outcome\" column, 0 denotes someone that does NOT have diabetes, and 1 denotes someone that does.  \n",
    "import pandas as pd\n",
    "\n",
    "diabetes_df = pd.read_csv('datasets/pima_indians_diabetes.csv')\n",
    "\n",
    "# Attempt to drop rows with null values, but there are no null values in this dataset\n",
    "diabetes_df = diabetes_df.dropna()\n",
    "\n",
    "diabetes_df.describe()\n",
    "# Glucose, Blood Pressure, Skin Thickness, Insuline, BMI cannot be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glucose 0s: 5\n",
      "BloodPressure 0s: 35\n",
      "SkinThickness 0s: 227\n",
      "Insulin 0s: 374\n",
      "BMI 0s: 11\n"
     ]
    }
   ],
   "source": [
    "print('Glucose 0s: {}'.format(diabetes_df[diabetes_df.Glucose == 0].shape[0]))\n",
    "print('BloodPressure 0s: {}'.format(diabetes_df[diabetes_df.BloodPressure == 0].shape[0]))\n",
    "print('SkinThickness 0s: {}'.format(diabetes_df[diabetes_df.SkinThickness == 0].shape[0]))\n",
    "print('Insulin 0s: {}'.format(diabetes_df[diabetes_df.Insulin == 0].shape[0]))\n",
    "print('BMI 0s: {}'.format(diabetes_df[diabetes_df.BMI == 0].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because there are small amounts of 0s for Glucose, BloodPressure, and BMI, I will drop those rows.\n",
    "clean_df = diabetes_df[diabetes_df.Glucose != 0]\n",
    "clean_df = clean_df[clean_df.BloodPressure != 0]\n",
    "clean_df = clean_df[clean_df.BMI != 0]\n",
    "\n",
    "# Because there are large amounts of 0s for SkinThickness and Insulin, I will drop those columns.\n",
    "clean_df.drop('SkinThickness', axis=1, inplace=True)\n",
    "clean_df.drop('Insulin', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store outcomes in labelss\n",
    "diabetes_labels = clean_df['Outcome']\n",
    "\n",
    "# Drop Outcomes column\n",
    "clean_df.drop('Outcome', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.7679558011049724\n",
      "f1 score: 0.7699054837678644\n"
     ]
    }
   ],
   "source": [
    "# Use train_test_split to split the data into X_train, X_test, y_train, and y_test variables\n",
    "X_train, X_test, y_train, y_test = train_test_split(clean_df, diabetes_labels)\n",
    "\n",
    "# Create a GaussianNB() object and fit it using the training data\n",
    "diabetes_clf = GaussianNB()\n",
    "diabetes_clf.fit(X_train, y_train)\n",
    "\n",
    "# Use the fitted model to create predictions for the X_test data.\n",
    "diabetes_preds = diabetes_clf.predict(X_test)\n",
    "\n",
    "# See scores for model\n",
    "print(\"accuracy score: {}\".format(accuracy_score(y_test, diabetes_preds)))\n",
    "print(\"f1 score: {}\".format(f1_score(y_test, diabetes_preds, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try scaling diabetes dataset and training and testing model with scaled dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScaler() Object. \n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Call scaler.fit() on the X_vals that will be rescaled.\n",
    "scaler.fit(clean_df)\n",
    "\n",
    "# Bind the newly scaled X_vals to scaled_X_vals by calling scaler.transform() on X_vals.\n",
    "scaled_X_vals = scaler.transform(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.7513812154696132\n",
      "f1 score: 0.7546267738128319\n"
     ]
    }
   ],
   "source": [
    "# Use train_test_split to split the data into X_train, X_test, y_train, and y_test variables\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X_vals, diabetes_labels)\n",
    "\n",
    "# Create a GaussianNB() object and fit it using the training data\n",
    "scale_clf = GaussianNB()\n",
    "scale_clf.fit(X_train, y_train)\n",
    "\n",
    "# Use the fitted model to create predictions for the X_test data.\n",
    "scale_preds = scale_clf.predict(X_test)\n",
    "\n",
    "# See scores for model\n",
    "print(\"accuracy score: {}\".format(accuracy_score(y_test, scale_preds)))\n",
    "print(\"f1 score: {}\".format(f1_score(y_test, scale_preds, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold 0] score: 0.68493\n",
      "[fold 1] score: 0.80822\n",
      "[fold 2] score: 0.71233\n",
      "[fold 3] score: 0.71233\n",
      "[fold 4] score: 0.73611\n",
      "[fold 5] score: 0.79167\n",
      "[fold 6] score: 0.77778\n",
      "[fold 7] score: 0.86111\n",
      "[fold 8] score: 0.72222\n",
      "[fold 9] score: 0.81944\n",
      "\n",
      "\n",
      "[fold 0] score: 0.73973\n",
      "[fold 1] score: 0.78082\n",
      "[fold 2] score: 0.76712\n",
      "[fold 3] score: 0.72603\n",
      "[fold 4] score: 0.72603\n",
      "[fold 5] score: 0.76389\n",
      "[fold 6] score: 0.77778\n",
      "[fold 7] score: 0.83333\n",
      "[fold 8] score: 0.72222\n",
      "[fold 9] score: 0.83099\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "\n",
    "# Create a KFold object and StratifiedKFold object with 10 splits / folds\n",
    "k_fold = KFold(n_splits=10)\n",
    "strat_k_fold = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# Create a new GaussianNB() object for k_fold\n",
    "gaussian_clf = GaussianNB()\n",
    "\n",
    "# Train and get score of gaussian_clf for all 10 splits of k_fold\n",
    "for k, (train, test) in enumerate(k_fold.split(clean_df, diabetes_labels)):\n",
    "    gaussian_clf.fit(clean_df.iloc[train], diabetes_labels.iloc[train])\n",
    "    print(\"[fold {0}] score: {1:.5f}\".format(k, gaussian_clf.score(clean_df.iloc[test], diabetes_labels.iloc[test])))\n",
    "\n",
    "# .iloc deals with inconsistencies between Pandas DataFrame indexing versus NumPy ndarray indexing \n",
    "# K_fold was not returning non-continuous indices of clean_df and diabetes_labels, use .iloc for diabetes_labels\n",
    "\n",
    "# Train and get score of gaussian_clf for all 10 splits of strat_k_fold\n",
    "print('\\n')\n",
    "for k, (train, test) in enumerate(strat_k_fold.split(clean_df, diabetes_labels)):\n",
    "    gaussian_clf.fit(clean_df.iloc[train], diabetes_labels.iloc[train])\n",
    "    print(\"[fold {0}] score: {1:.5f}\".format(k, gaussian_clf.score(clean_df.iloc[test], diabetes_labels.iloc[test])))\n",
    "\n",
    "# KFold and StratifiedKFold don't appear that different for this diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.68493151  0.80821918  0.71232877  0.71232877  0.73611111  0.79166667\n",
      "  0.77777778  0.86111111  0.72222222  0.81944444]\n"
     ]
    }
   ],
   "source": [
    "# Try using cross_val_score() for scores instead of iterating over k_fold\n",
    "print(cross_val_score(gaussian_clf, clean_df, diabetes_labels, cv=k_fold)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
